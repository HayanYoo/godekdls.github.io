---
title: Deploying with kubectl
navTitle: kubectl
category: Spring Cloud Data Flow
order: 13
permalink: /Spring%20Cloud%20Data%20Flow/installation.kubernetes.kubectl/
description: kubectl을 이용해 쿠버네티스 환경에 Spring Cloud Data Flow 설치하기
image: ./../../images/springclouddataflow/logo.png
lastmod: 2021-12-02T00:33:00+09:00
comments: true
originalRefName: 스프링 클라우드 데이터 플로우
originalRefLink: https://dataflow.spring.io/docs/installation/kubernetes/kubectl/
parent: Installation
parentUrl: /Spring%20Cloud%20Data%20Flow/installation/
subparent: Kubernetes
subparentUrl: /Spring%20Cloud%20Data%20Flow/installation.kubernetes/
---

---

`kubectl`을 이용해 설치하려면 쿠버네티스 설정 파일이 필요하다.

다양한 애플리케이션과 서비스들을 배포하려면 서비스 디스커버리가 필요하다. 그러려면 메타데이터 셋이 있어야 한다. 해당 코드를 확인해보고 싶다면 아래 명령어를 입력해라:

```bash
git clone https://github.com/spring-cloud/spring-cloud-dataflow
cd spring-cloud-dataflow
git checkout v2.9.1
```

> Minikube를 사용한다면 [Minikube 리소스 설정하기](../installation.kubernetes.creatingcluster/#setting-minikube-resources)에서 CPU와 RAM 리소스 요구 사항을 확인해봐라.

### 목차

- [Choose a Message Broker](#choose-a-message-broker)
- [Deploy Services, Skipper, and Data Flow](#deploy-services-skipper-and-data-flow)
  + [Deploy MySQL](#deploy-mysql)
  + [Enable Monitoring](#enable-monitoring)
    * [Prometheus and Grafana](#prometheus-and-grafana)
    * [Wavefront](#wavefront)
  + [Create Data Flow Role Bindings and Service Account](#create-data-flow-role-bindings-and-service-account)
  + [Deploy Skipper](#deploy-skipper)
  + [Deploy Data Flow Server](#deploy-data-flow-server)

---

## Choose a Message Broker

배포한 애플리케이션끼리 서로 통신하려면 메세지 브로커를 하나 선택해야 한다. 샘플 deployment, service YAML 파일에선 RabbitMQ와 카프카를 위한 설정을 제공하고 있다. 이 중 하나의 메세지 브로커만 설정하면 된다.

- RabbitMQ

  RabbitMQ 서비스를 시작하려면 다음 명령어를 실행해라:

  ```sh
  kubectl create -f src/kubernetes/rabbitmq/
  ```

  deployment, pod, service 리소스가 실행 중인지는 `kubectl get all -l app=rabbitmq`를 통해 확인할 수 있다. 이후 리소스를 정리할 땐 `kubectl delete all -l app=rabbitmq`를 실행해라.
  
- Kafka

  카프카 서비스를 시작하려면 다음 명령어를 실행해라:

  ```sh
  kubectl create -f src/kubernetes/kafka/
  ```

  deployment, pod, service 리소스가 실행 중인지는 `kubectl get all -l app=kafka`를 통해 확인할 수 있다. 이후 리소스를 정리할 땐 `kubectl delete all -l app=kafka`를 실행해라.

---

## Deploy Services, Skipper, and Data Flow

Data Flow는 여러 가지 서비스와 함께 배포해야 한다. 이어지는 하위 섹션에선 그 방법들에 대해 설명한다:

1. [MySQL 배포하기](#deploy-mysql)
2. [모니터링 활성화하기](#enable-monitoring)
3. [Data Flow 롤 바인딩과 서비스 어카운트 생성하기](#create-data-flow-role-bindings-and-service-account)
4. [Skipper 배포하기](#deploy-skipper)
5. [Data Flow 서버 배포하기](#deploy-data-flow-server)

### Deploy MySQL

이 가이드에선 MySQL을 사용하지만, MySQL 대신 Postgres나 H2 데이터베이스를 사용해도 된다. 이 세 가지 데이터베이스 모두 JDBC 드라이버가 포함돼 있다. MySQL 외에 다른 데이터베이스를 사용하려면 반드시 데이터베이스 URL과 드라이버 클래스명 설정을 바꿔줘야 한다.

> **비밀번호 관리**
>
> 보안을 강화하고 싶다면 `src/kubernetes/mysql/mysql-deployment.yaml` 파일을 수정해 비밀번호를 설정할 수 있다. 비밀번호를 수정한다면 `src/kubernetes/mysql/mysql-secrets.yaml` 파일에도 반드시 비밀번호를 base64로 인코딩한 문자열을 제공해야 한다.

MySQL 서비스를 시작하려면 다음 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/mysql/
```

deployment, pod, service 리소스가 실행 중인지는 `kubectl get all -l app=mysql`을 통해 확인할 수 있다. 이후 리소스를 정리할 땐 `kubectl delete all,pvc,secrets -l app=mysql`을 실행하면 된다.

### Enable Monitoring

모니터링을 활성화하는 방법은 모니터링 플랫폼에 따라 다르다:

- [프로메테우스와 그라파나](#prometheus-and-grafana)
- [Wavefront](#wavefront)

#### Prometheus and Grafana

[Prometheus RSocket](https://github.com/micrometer-metrics/prometheus-rsocket-proxy) 구현체를 사용하면 모든 스트림/태스크 애플리케이션과 하나 이상의 `Prometheus RSocket Proxy` 인스턴스 간에 지속적인 양방향<sup>bidirectional</sup> `RSocket` 커넥션을 구축할 수 있다. 프로메테우스는 각 프록시 인스턴스를 스크랩하도록 설정된다. 프록시들은 돌아가며 이 커넥션을 통해 각 애플리케이션에서 메트릭을 가져온다. 스크랩한 메트릭은 그라파나 대시보드를 통해 확인할 수 있다. 그라파나 대시보드는 기본으로 프로메테우스 데이터 소스 커넥션이 설정되 있으며, Data Flow 전용 대시보드가 만들어져 있어서 데이터 파이프라인에 있는 스트리밍과 태스크 애플리케이션들을 모니터링할 수 있다.

> **메모리 리소스**
>
> Minikube를 사용한다면 [Minikube 리소스 설정하기](../installation.kubernetes.creatingcluster/#setting-minikube-resources)에서 CPU와 RAM 리소스 요구 사항을 확인해봐라.
>
> 프로메테우스와 그라파나를 실행하려면 메모리를 최소한 2GB~3GB 정도는 추가로 확보해야 한다.

클러스터 롤, 바인딩, 서비스 어카운트 생성하려면 다음 명령어를 실행해라.

```sh
kubectl create -f src/kubernetes/prometheus/prometheus-clusterroles.yaml
kubectl create -f src/kubernetes/prometheus/prometheus-clusterrolebinding.yaml
kubectl create -f src/kubernetes/prometheus/prometheus-serviceaccount.yaml
```

Prometheus RSocket Proxy를 배포하려면 아래 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/prometheus-proxy/
```

deployment, pod, service 리소스가 실행 중인지는 `kubectl get all -l app=prometheus-proxy`를 통해 확인할 수 있다. 이후 리소스를 정리할 땐 `kubectl delete all,cm,svc -l app=prometheus-proxy`를 실행하면 된다. 프로메테우스 프록시에 대한 롤, 바인딩, 서비스 어카운트를 정리하려면 아래 명령어를 실행해라:

```sh
kubectl delete clusterrole,clusterrolebinding,sa -l app=prometheus-proxy
```

프로메테우스를 배포하려면 다음 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/prometheus/prometheus-configmap.yaml
kubectl create -f src/kubernetes/prometheus/prometheus-deployment.yaml
kubectl create -f src/kubernetes/prometheus/prometheus-service.yaml
```

deployment, pod, service 리소스가 실행 중인지는 `kubectl get all -l app=prometheus`를 통해 확인할 수 있다. 이후 리소스를 정리할 땐 `kubectl delete all,cm,svc -l app=prometheus`를 실행하면 된다. 프로메테우스에 대한 롤, 바인딩, 서비스 어카운트를 정리하려면 아래 명령어를 실행해라:

```sh
kubectl delete clusterrole,clusterrolebinding,sa -l app=prometheus
```

그라파나를 배포하려면 다음 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/grafana/
```

deployment, pod, service 리소스가 실행 중인지는 `kubectl get all -l app=grafana`를 통해 확인할 수 있다. 이후 리소스를 정리할 땐 `kubectl delete all,cm,svc,secrets -l app=grafana`를 실행하면 된다.

> `src/kubernetes/server/server-config.yaml`에서 아래에 있는 부분은 `url` 속성 값을 그라파나를 실행하는 주소와 포트에 맞게 수정해야 한다. Minikube에선 `minikube service --url grafana`로 그라파나 주소를 확인할 수 있다. 이 설정은 웹 브라우저를 통해 대시보드에 접근할 때 그라파나 링크에 액세스하기 위해 필요하다.
>
> ```yml
> spring:
>   cloud:
>     dataflow:
>       metrics.dashboard:
>         url: 'https://grafana:3000'
> ```

그라파나 대시보드에서 사용하는 디폴트 credential의 username은 `admin`, password는 `password`다. 이 기본값은 `src/kubernetes/grafana/grafana-secret.yaml` 파일을 수정해서 변경하면 된다.

Spring Cloud Skipper 서버에서 프로메테우스를 활성화하려면 Data Flow 설정을 Skipper의 설정 파일(`src/kubernetes/skipper/skipper-config-{kafka|rabbit}.yaml`)로 가져오면 된다:

```yaml
management:
  metrics:
    export:
      prometheus:
        enabled: true
        rsocket:
          enabled: true
          host: prometheus-proxy
          port: 7001
```

메트릭과 모니터링을 위한 프로메테우스, 그라파나를 배포하고 싶지 않다면 `src/kubernetes/server/server-config.yaml`에서 아래 섹션을 제거해야 한다:

```yaml
management:
  metrics:
    export:
      prometheus:
        enabled: true
        rsocket:
          enabled: true
          host: prometheus-proxy
          port: 7001
spring:
  cloud:
    dataflow:
      metrics.dashboard:
        url: 'https://grafana:3000'
```

#### Wavefront

배포된 스트림/태스크 관련 메트릭과 함께 Spring Cloud Data Flow 서버에 대한 메트릭도 Wavefront 서비스로 전송할 수 있다. Wavefront를 활성화하려면 먼저 Wavefront URL과 API 토큰이 있어야 한다.

먼저 `wavefront-secret.yaml`이란 파일에 API 토큰을 인코딩할 시크릿을 만들어보자:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: wavefront-api
  labels:
    app: wavefront
data:
  wavefront-api-token: bXl0b2tlbg==
```

`wavefront-api-token`에 있는 값은 API 토큰을 나타내는 문자열을 base64로 인코딩한 값이다. 시크릿에 대한 자세한 내용은 [쿠버네티스 문서](https://kubernetes.io/docs/concepts/configuration/secret/)를 참고해라.

이 시크릿을 생성해라:

```sh
kubectl create -f wavefront-secret.yaml
```

이 시크릿을 마운트하고 Spring Cloud Data Flow에서 사용할 수 있게 만들려면 `src/kubernetes/server/server-deployment.yaml` 파일에 다음 내용을 추가해라:

> 시크릿 mountPath는 `SPRING_CLOUD_KUBERNETES_SECRETS_PATHS`와 동일한 경로 내에 있어야 한다.

```yaml
spec:
  containers:
    - name: scdf-server
      volumeMounts:
        - name: wavefront-api
          mountPath: /etc/secrets/wavefront-api
          readOnly: true
  volumes:
    - name: wavefront-api
      secret:
        secretName: wavefront-api
```

Wavefront는 필요에 따라 Spring Cloud Data Flow 서버, 스트림, 태스크에 활성화할 수 있다. 각각은 독립적으로 설정되기 때문에 하나만 설정하거나 모두를 설정하는 것도 가능하다.

Spring Cloud Data Flow 서버에 Wavefront를 활성화하려면 `src/kubernetes/server/server-config.yaml` 파일에 다음 내용을 추가해라:

```yaml
data:
  application.yaml: |-
    management:
      metrics:
        export:
          wavefront:
            enabled: true
            api-token: ${wavefront-api-token}
            uri: https://yourwfuri.wavefront.com
            source: yoursourcename
```

`uri`와 `source`는 각자 환경에 맞는 값으로 변경해라. `api-token` 값은 시크릿을 통해 자동으로 리졸브된다.

기본적으로 위 설정은 배포된 스트림과 태스크에도 자동으로 적용되어 해당 메트릭을 Wavefront로 전송한다. 기본값을 변경하려면 `applicationProperties.stream.*`과 `applicationProperties.task.*`를 사용해라.

Spring Cloud Skipper 서버에서 Wavefront를 활성화하려면 Data Flow 설정을 Skipper의 설정 파일(`src/kubernetes/skipper/skipper-config-{kafka|rabbit}.yaml`)로 가져온 뒤 `src/kubernetes/skipper/skipper-deployment.yaml` 파일에 `wavefront-api` 볼륨을 추가하면 된다.

> `src/kubernetes/server/server-config.yaml`에서 아래 있는 부분은 `url` 속성 값을 Wavefront 대시보드를 실행하는 주소와 포트에 맞게 수정해야 한다. 이 설정은 웹 브라우저를 통해 대시보드에 접근할 때 Wavefront 링크에 액세스하기 위해 필요하다.
>
> ```yaml
> spring:
>   cloud:
>     dataflow:
>       metrics.dashboard:
>         url: 'https://yourwfuri.wavefront.com'
>         type: 'WAVEFRONT'
> ```

### Create Data Flow Role Bindings and Service Account

롤 바인딩과 서비스 어카운트를 생성하려면 다음 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/server/server-roles.yaml
kubectl create -f src/kubernetes/server/server-rolebinding.yaml
kubectl create -f src/kubernetes/server/service-account.yaml
```

사용 가능한 롤과 서비스 어카운트는 `kubectl get roles`와 `kubectl get sa`를 통해 확인할 수 있다.

롤, 바인딩, 서비스 어카운트를 정리하려면 다음 명령어를 사용해라:

```sh
kubectl delete role scdf-role
kubectl delete rolebinding scdf-rb
kubectl delete serviceaccount scdf-sa
```

### Deploy Skipper

Data Flow는 스트림 라이프사이클 관리를 Skipper에 위임한다. 따라서 스트림 관리 기능을 이용하려면 [Skipper](https://spring.io/projects/spring-cloud-skipper)를 배포해야 한다.

deployment는 `src/kubernetes/skipper/skipper-deployment.yaml` 파일에 정의돼 있다. 배포할 Skipper 버전을 제어하고 싶다면, 다음과 같이 컨테이너 스펙에서 도커 이미지에 사용하는 태그를 수정하면 된다:

```yml
spec:
  containers:
    - name: skipper
      image: springcloud/spring-cloud-skipper-server:2.8.1 #
```

- 버전은 원하는대로 변경하면 된다.

> **멀티 플랫폼 지원**
>
> Skipper에선 [플랫폼](https://docs.spring.io/spring-cloud-skipper/docs/current/reference/htmlsingle/#using-platforms)이라는 개념이 있기 때문에, "accounts"는 프로젝트 성격에 따라 정의하는 게 좋다.

RabbitMQ를 메세징 미들웨어로 사용하려면 아래 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/skipper/skipper-config-rabbit.yaml
```

카프카를 메세징 미들웨어로 사용하려면 아래 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/skipper/skipper-config-kafka.yaml
```

추가로 [Apache Kafka Streams Binder](https://docs.spring.io/spring-cloud-stream-binder-kafka/docs/current/reference/html/spring-cloud-stream-binder-kafka.html#_kafka_streams_binder)를 사용하려면, 다음과 같이 `src/kubernetes/skipper/skipper-config-kafka.yaml`에 있는 `environmentVariables` 속성을 Kafka Streams Binder 설정을 포함하도록 업데이트해라:

```yaml
environmentVariables: 'SPRING_CLOUD_STREAM_KAFKA_BINDER_BROKERS=kafka-broker:9092,SPRING_CLOUD_STREAM_KAFKA_BINDER_ZK_NODES=${KAFKA_ZK_SERVICE_HOST}:${KAFKA_ZK_SERVICE_PORT}, SPRING_CLOUD_STREAM_KAFKA_STREAMS_BINDER_BROKERS=kafka-broker:9092,SPRING_CLOUD_STREAM_KAFKA_STREAMS_BINDER_ZK_NODES=${KAFKA_ZK_SERVICE_HOST}:${KAFKA_ZK_SERVICE_PORT}'
```

Spring Cloud Data Flow와 함께 일할 서버로 Skipper를 시작하려면 다음 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/skipper/skipper-deployment.yaml
kubectl create -f src/kubernetes/skipper/skipper-svc.yaml
```

deployment, pod, service 리소스가 실행 중인지는 `kubectl get all -l app=skipper`를 통해 확인할 수 있다. 이후 리소스를 정리할 땐 `kubectl delete all,cm -l app=skipper`를 실행하면 된다.

### Deploy Data Flow Server

deployment는 `src/kubernetes/server/server-deployment.yaml` 파일에 정의돼 있다. 배포할 Spring Cloud Data Flow 서버 버전을 제어하고 싶다면, 다음과 같이 컨테이너 스펙에서 도커 이미지에 사용하는 태그를 수정하면 된다:

```yaml
spec:
  containers:
    - name: scdf-server
      image: springcloud/spring-cloud-dataflow-server:2.9.1
```

배포하고 싶은 Spring Cloud Data Flow 서버 버전이 있다면 반드시 명시해줘야 한다. 원하는 버전으로 변경하면 된다. 이 문서는 `2.9.1` 릴리즈를 기반으로 설명한다. `BUILD-SNAPSHOT` 릴리즈는 도커 `latest` 태그를 이용할 수 있다. Skipper 서비스가 실행 중이어야 하며, `src/kubernetes/server/server-deployment.yaml`에 있는 `SPRING_CLOUD_SKIPPER_CLIENT_SERVER_URI` 프로퍼티는 이 Skipper 서비스를 가리켜야 한다.

Data Flow 서버는 Fabric8 자바 클라이언트 라이브러리를 통해 쿠버네티스 클러스터에 연결한다. 클러스터에 연결할 [클라이언트를 구성하는 방법](https://github.com/fabric8io/kubernetes-client#configuring-the-client)은 여러 가지가 있다. Data Flow 서버를 쿠버네티스에 배포할 때 필요한 값들은 환경 변수를 통해 설정한다. 또한 [`ConfigMap`](https://kubernetes.io/docs/user-guide/configmap/)과 [`Secrets`](https://kubernetes.io/docs/user-guide/secrets/) 설정에 액세스할 땐 [Spring Cloud Kubernetes 라이브러리](https://github.com/spring-cloud/spring-cloud-kubernetes)를 사용한다.

RabbitMQ의 `ConfigMap` 설정은 `src/kubernetes/skipper/skipper-config-rabbit.yaml` 파일에, 카프카에 대한 설정은 `src/kubernetes/skipper/skipper-config-kafka.yaml` 파일에 지정한다.

MySQL 시크릿은 `src/kubernetes/mysql/mysql-secrets.yaml` 파일에 위치해 있다. MySQL의 비밀번호를 변경했다면 `src/kubernetes/mysql/mysql-secrets.yaml` 파일도 수정해줘야 한다. 모든 시크릿은 base64로 인코딩해야 한다.

디폴트 설정으로 컨피그맵을 생성하려면 아래 명령어를 실행해라:

```sh
kubectl create -f src/kubernetes/server/server-config.yaml
```

이제 다음 명령어를 통해 서버 deployment를 생성해야 한다:

```sh
kubectl create -f src/kubernetes/server/server-svc.yaml
kubectl create -f src/kubernetes/server/server-deployment.yaml
```

deployment, pod, service 리소스가 실행 중인지는 `kubectl get all -l app=scdf-server`를 통해 확인할 수 있다. 이후 리소스를 정리할 땐 `kubectl delete all,cm -l app=scdf-server`를 실행하면 된다.

`scdf-server`에 할당된 `EXTERNAL_IP` 주소는 `kubectl get svc scdf-server` 명령어를 사용해 찾을 수 있다. 나중에 쉘에서 연결할 땐 이 주소를 사용하면 된다. 다음은 IP를 확인하는 예시다 (출력 문구 포함):

```sh
kubectl get svc scdf-server
NAME         CLUSTER-IP       EXTERNAL-IP       PORT(S)    AGE
scdf-server  10.103.246.82    130.211.203.246   80/TCP     4m
```

이때 사용해야 하는 URL은 'https://130.211.203.246'이다.

Minikube를 사용하는 경우엔 외부 로드 밸런서가 없으며 `EXTERNAL_IP`는 `<pending>`으로 표시될 거다. 이땐 `scdf-server` 서비스에 할당된 `NodePort`를 사용해야 한다. 아래 명령어를 통해 사용할 URL을 조회할 수 있다 (출력 문구도 함께 표기했다):

```sh
minikube service --url scdf-server
https://192.168.99.100:31991
```